<tag name="TECHNIQUE" value="start"/>Lattice-Based Search<tag name="TECHNIQUE" value="end"/> For <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>Spoken Utterance Retrieval<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> .
Recent work on <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>spoken document retrieval<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> has suggested that it is adequate to take the singlebest output of ASR , and perform text retrieval on this output .
This is reasonable enough for the task of retrieving broadcast news stories , where word error rates are relatively low , and the stories are long enough to contain much redundancy .
But it is patently not reasonable if one 's task is to retrieve a short snippet of speech in a domain where WER 's can be as high as 50 % ; such would be the situation with teleconference speech , where one 's task is to find if and when a participant uttered a certain phrase .
In this paper we propose an <tag name="TECHNIQUE" value="start"/><tag name="FOCUS" value="start"/>indexing<tag name="FOCUS" value="end"/><tag name="TECHNIQUE" value="end"/> procedure for <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>spoken utterance retrieval<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> that works on <tag name="TECHNIQUE" value="start"/>lattices<tag name="TECHNIQUE" value="end"/> rather than just single-best text .
We demonstrate that this procedure can improve F scores by over five points compared to singlebest retrieval on tasks with poor WER and low redundancy .
The representation is flexible so that we can represent both <tag name="TECHNIQUE" value="start"/>word lattices<tag name="TECHNIQUE" value="end"/> , as well as <tag name="TECHNIQUE" value="start"/>phone lattices<tag name="TECHNIQUE" value="end"/> , the latter being important for improving performance when searching for phrases containing OOV words .