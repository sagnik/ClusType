<tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>Text Classification<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> By <tag name="TECHNIQUE" value="start"/><tag name="FOCUS" value="start"/>Bootstrapping With Keywords , EM And Shrinkage<tag name="FOCUS" value="end"/><tag name="TECHNIQUE" value="end"/> .
When applying <tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>text classification<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> to complex tasks , it is tedious and expensive to hand-label the large amounts of training data necessary for good performance .
This paper presents an alternative approach to <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>text classification<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> that requires no labeled documentsi instead , it uses a small set of keywords per class , a class hierarchy and a large quantity of easilyobtained unlabeled documents .
The keywords are used to assign approximate labels to the unlabeled documents by termmatching .
These preliminary labels become the starting point for a <tag name="TECHNIQUE" value="start"/>bootstrapping<tag name="TECHNIQUE" value="end"/> process that learns a <tag name="TECHNIQUE" value="start"/>naive Bayes classifier<tag name="TECHNIQUE" value="end"/> using <tag name="TECHNIQUE" value="start"/>Expectation-Maximization and hierarchical shrinkage<tag name="TECHNIQUE" value="end"/> .
When classifying a complex data set of computer science research papers into a 70-leaf topic hierarchy , the keywords alone provide 45 % accuracy .
The classifier learned by bootstrapping reaches 66 % accuracy , a level close to human agreement .