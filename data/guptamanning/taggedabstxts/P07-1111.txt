A Re-examination of <tag name="TECHNIQUE" value="start"/>Machine Learning<tag name="TECHNIQUE" value="end"/> Approaches for <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>Sentence-Level MT Evaluation<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> .
Recent studies suggest that <tag name="TECHNIQUE" value="start"/>machine learning<tag name="TECHNIQUE" value="end"/> can be applied to develop good automatic <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>evaluation<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> metrics for machine translated sentences .
This paper further analyzes aspects of learning that impact performance .
We argue that previously proposed approaches of training a HumanLikeness classifier is not as well correlated with human judgments of translation quality , but that <tag name="TECHNIQUE" value="start"/>regression-based learning<tag name="TECHNIQUE" value="end"/> produces more reliable metrics .
We demonstrate the feasibility of <tag name="TECHNIQUE" value="start"/>regression-based<tag name="TECHNIQUE" value="end"/> metrics through empirical analysis of learning curves and generalization studies and show that they can achieve higher correlations with human judgments than standard automatic metrics .