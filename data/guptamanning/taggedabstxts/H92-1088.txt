Towards Using <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>Prosody<tag name="TECHNIQUE" value="end"/> In <tag name="DOMAIN" value="start"/>Speech Recognition\/Understanding <tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> Systems : Differences Between Read And Spontaneous Speech .
A persistent problem for keyword-driven <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>speech recognition<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> systems is that users often embed the to-be-recognized words or phrases in longer utterances .
The recognizer needs to locate the relevant sections of the speech signal and ignore extraneous words .
Prosody might provide an extra source of information to help locate target words embedded in other speech .
In this paper we examine some <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>prosodic <tag name="TECHNIQUE" value="end"/><tag name="FOCUS" value="end"/> characteristics of 160 such utterances and compare matched read and spontaneous versions .
Half of the utterances are from a corpus of spontaneous answers to requests for the name of a city , recorded from calls to Directory Assistance Operators .
The other half are the same word strings read by volunteers attempting to model the real dialogue .
Results show a consistent pattern across both sets of data : embedded city names almost always bear nuclear pitch accents and are in their own intonational phrases .
However the distributions of tonal make-up of these <tag name="TECHNIQUE" value="start"/><tag name="FOCUS" value="start"/>prosodic features<tag name="FOCUS" value="end"/><tag name="TECHNIQUE" value="end"/> differ markedly in read versus spontaneous speech , implying that if algorithms that exploit these prosodic regularities are trained on read speech , then the probabilities are likely to be incorrect models of real user speech .