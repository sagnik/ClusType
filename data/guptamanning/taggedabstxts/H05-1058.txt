<tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>Part-Of-Speech Tagging<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> Using <tag name="TECHNIQUE" value="start"/>Virtual Evidence And Negative Training<tag name="TECHNIQUE" value="end"/> .
We present a <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>part-of-speech tagger<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> which introduces two new concepts : <tag name="TECHNIQUE" value="start"/>virtual evidence<tag name="TECHNIQUE" value="end"/> in the form of an observed child node , and <tag name="TECHNIQUE" value="start"/>negative training<tag name="TECHNIQUE" value="end"/> data to learn the conditional probabilities for the observed child .
Associated with each word is a exible feature-set which can include binary ags , neighboring words , etc. .
The conditional probability of Tag given Word + Features is implemented using a <tag name="TECHNIQUE" value="start"/>factored language-model with back-off<tag name="TECHNIQUE" value="end"/> to avoid data sparsity problems .
This model remains within the framework of <tag name="TECHNIQUE" value="start"/>Dynamic Bayesian Networks<tag name="TECHNIQUE" value="end"/> -LRB- <tag name="TECHNIQUE" value="start"/>DBNs<tag name="TECHNIQUE" value="end"/> -RRB- and is conditionally-structured , but resolves the label bias problem inherent in the conditional Markov  model -LRB- CMM -RRB- .