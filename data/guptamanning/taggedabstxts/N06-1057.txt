<tag name="FOCUS" value="start"/>ParaEval<tag name="FOCUS" value="end"/> : Using <tag name="TECHNIQUE" value="start"/>Paraphrases<tag name="TECHNIQUE" value="end"/> To <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>Evaluate Summaries<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> Automatically .
<tag name="FOCUS" value="start"/>ParaEval<tag name="FOCUS" value="end"/> is an automated <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>evaluation<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> method for comparing reference and peer <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>summaries<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> .
It facilitates a tieredcomparison strategy where recall-oriented global optimal and local greedy searches for <tag name="TECHNIQUE" value="start"/>paraphrase<tag name="TECHNIQUE" value="end"/> matching are enabled in the top tiers .
We utilize a domainindependent <tag name="TECHNIQUE" value="start"/>paraphrase<tag name="TECHNIQUE" value="end"/> table extracted from a large bilingual parallel corpus using methods from <tag name="TECHNIQUE" value="start"/>Machine Translation<tag name="TECHNIQUE" value="end"/> -LRB- <tag name="TECHNIQUE" value="start"/>MT<tag name="TECHNIQUE" value="end"/> -RRB- .
We show that the quality of <tag name="FOCUS" value="start"/>ParaEval<tag name="FOCUS" value="end"/> 's evaluations , measured by correlating with human judgments , closely resembles that of ROUGE 's .