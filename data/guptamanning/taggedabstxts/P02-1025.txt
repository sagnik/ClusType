A Study On <tag name="TECHNIQUE" value="start"/>Richer Syntactic Dependencies<tag name="TECHNIQUE" value="end"/> For <tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>Structured Language Modeling<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> .
We study the impact of <tag name="TECHNIQUE" value="start"/>richer syntactic dependencies<tag name="TECHNIQUE" value="end"/> on the performance of the <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>structured language model<tag name="FOCUS" value="end"/> <tag name="DOMAIN" value="end"/> -LRB- <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>SLM<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> -RRB- along three dimensions : <tag name="DOMAIN" value="start"/>parsing<tag name="DOMAIN" value="end"/> accuracy -LRB- LP\/LR -RRB- , perplexity -LRB- PPL -RRB- and worderror-rate -LRB- WER , N-best re-scoring -RRB- .
We show that our models achieve an improvement in LP\/LR , PPL and\/or WER over the reported baseline results using the SLM on the UPenn Treebank and Wall Street Journal -LRB- WSJ -RRB- corpora , respectively .
Analysis of <tag name="DOMAIN" value="start"/>parsing<tag name="DOMAIN" value="end"/> performance shows correlation between the quality of the parser -LRB- as measured by precision\/recall -RRB- and the <tag name="DOMAIN" value="start"/>language model<tag name="DOMAIN" value="end"/> performance -LRB- PPL and WER -RRB- .
A remarkable fact is that the enriched <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>SLM<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> outperforms the baseline 3-gram model in terms of WER by 10 % when used in isolation as a second pass -LRB- N-best re-scoring -RRB- language model .