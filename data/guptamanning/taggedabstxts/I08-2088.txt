Method of <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>Selecting Training Data<tag name="TECHNIQUE" value="end"/><tag name="FOCUS" value="end"/> to Build a Compact and Efficient <tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>Translation <tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> Model .
Target task matched parallel corpora are required for <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>statistical translation<tag name="FOCUS" value="end"/> <tag name="DOMAIN" value="end"/> model training .
However , training corpora sometimes include both target task matched and unmatched sentences .
In such a case , training set selection can reduce the size of the translation model .
In this paper , we propose a <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>training set selection<tag name="TECHNIQUE" value="end"/><tag name="FOCUS" value="end"/> method for <tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>translation <tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> model training using <tag name="TECHNIQUE" value="start"/>linear<tag name="TECHNIQUE" value="end"/> <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>translation<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> model interpolation and a <tag name="TECHNIQUE" value="start"/>language model<tag name="TECHNIQUE" value="end"/> technique .
According to the experimental results , the proposed method reduces the translation model size by 50 % and improves BLEU score by 1.76 % in comparison with a baseline training corpus usage .