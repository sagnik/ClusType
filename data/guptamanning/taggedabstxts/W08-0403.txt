<tag name="TECHNIQUE" value="start"/>Prior Derivation<tag name="TECHNIQUE" value="end"/> Models For Formally <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>Syntax-Based<tag name="TECHNIQUE" value="end"/> <tag name="DOMAIN" value="start"/> Translation<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> Using <tag name="TECHNIQUE" value="start"/>Linguistically Syntactic Parsing<tag name="TECHNIQUE" value="end"/> and <tag name="TECHNIQUE" value="start"/>Tree Kernels<tag name="TECHNIQUE" value="end"/> .
This paper presents an improved formally <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>syntax-based<tag name="TECHNIQUE" value="end"/> <tag name="DOMAIN" value="start"/>SMT<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> model , which is enriched by linguistically syntactic knowledge obtained from <tag name="TECHNIQUE" value="start"/>statistical constituent parsers<tag name="TECHNIQUE" value="end"/> .
We propose a linguistically-motivated <tag name="TECHNIQUE" value="start"/>prior derivation<tag name="TECHNIQUE" value="end"/> model to score hypothesis derivations on top of the baseline model during the translation decoding .
Moreover , we devise a fast <tag name="TECHNIQUE" value="start"/>training<tag name="TECHNIQUE" value="end"/> algorithm to achieve such improved models based on <tag name="TECHNIQUE" value="start"/>tree kernel<tag name="TECHNIQUE" value="end"/> methods .
Experiments on an English-to-Chinese task demonstrate that our proposed models outperformed the baseline formally syntaxbased models , while both of them achieved signi cant improvements over a state-of-theart phrase-based SMT system .