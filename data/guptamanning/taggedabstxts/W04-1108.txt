Combining <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>Neural Networks<tag name="TECHNIQUE" value="end"/> <tag name="FOCUS" value="end"/> And <tag name="TECHNIQUE" value="start"/>Statistics <tag name="TECHNIQUE" value="end"/>For Chinese <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>Word Sense Disambiguation<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> .
The input of network is the key problem for Chinese Word sense disambiguation utilizing the Neural Network .
This paper presents an input model of <tag name="TECHNIQUE" value="start"/><tag name="FOCUS" value="start"/>Neural Network<tag name="FOCUS" value="end"/><tag name="TECHNIQUE" value="end"/> that calculates the <tag name="TECHNIQUE" value="start"/>Mutual Information<tag name="TECHNIQUE" value="end"/> between contextual words and ambiguous word by using <tag name="TECHNIQUE" value="start"/>statistical<tag name="TECHNIQUE" value="end"/> method and taking the contextual words to certain number beside the ambiguous word according to -LRB- - M , + N -RRB- .
The experiment adopts triple-layer <tag name="TECHNIQUE" value="start"/>BP Neural Network<tag name="TECHNIQUE" value="end"/> model and proves how the size of training set and the value of M and N affect the performance of <tag name="TECHNIQUE" value="start"/>Neural Network<tag name="TECHNIQUE" value="end"/> model .
The experimental objects are six pseudowords owning three word-senses constructed according to certain principles .
Tested accuracy of our approach on a close-corpus reaches 90.31 % , , and 89.62 % on a open-corpus .
The experiment proves that the <tag name="TECHNIQUE" value="start"/>Neural Network<tag name="TECHNIQUE" value="end"/> model has good performance on <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>Word sense disambiguation<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> .