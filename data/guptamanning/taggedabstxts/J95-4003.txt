<tag name="TECHNIQUE" value="start"/>Modularity And Information Content Classes<tag name="TECHNIQUE" value="end"/> In <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>Principle-Based<tag name="TECHNIQUE" value="end"/> <tag name="DOMAIN" value="start"/>Parsing<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> .
In recent years models of parsing that are isomorphic to a <tag name="FOCUS" value="start"/><tag name="TECHNIQUE" value="start"/>principle-based theory of grammar<tag name="TECHNIQUE" value="end"/><tag name="FOCUS" value="end"/> -LRB- most notably Government and Binding -LRB- GB -RRB- Theory -RRB- have been proposed -LRB- Berwick et al. 1991 -RRB- .
These models are natural and direct implementations of the grammar , but they are not efficient , because GB is not a computationally modular theory .
This paper investigates one problem related to the tension between building linguistically based parsers and building efficient ones .
In particular , the issue of what is a linguistically motivated way of deriving a <tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>parser<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> from <tag name="TECHNIQUE" value="start"/><tag name="FOCUS" value="start"/>principle-based theories of grammar<tag name="FOCUS" value="end"/><tag name="TECHNIQUE" value="end"/> is explored .
It is argued that an efficient and faithful <tag name="DOMAIN" value="start"/><tag name="FOCUS" value="start"/>parser<tag name="FOCUS" value="end"/><tag name="DOMAIN" value="end"/> can be built by taking advantage of the way in which principles are stated .
To support this claim , two features of an implemented <tag name="FOCUS" value="start"/><tag name="DOMAIN" value="start"/>parser<tag name="DOMAIN" value="end"/><tag name="FOCUS" value="end"/> are discussed .
First , <tag name="TECHNIQUE" value="start"/>configurations and lexical information<tag name="TECHNIQUE" value="end"/> are precompiled separately into two tables -LRB- an X table and a table of <tag name="TECHNIQUE" value="start"/>lexical co-occurrence<tag name="TECHNIQUE" value="end"/> -RRB- which gives rise to more compact data structures .
Secondly , precomputation of <tag name="TECHNIQUE" value="start"/>syntactic features<tag name="TECHNIQUE" value="end"/> -LRB- O-roles , case , etc. -RRB- results in efficient computation of chains , because it reduces several problems of chain formation to a local computation , thus avoiding extensive search of the tree for an antecedent or extensive backtracking .
It is also shown that this method of building long-distance dependencies can be computed incrementally .